{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>exercise</th>\n",
       "      <th>technique</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/jake/code/jchaselubitz/vocal_patterns/d...</td>\n",
       "      <td>arpeggios</td>\n",
       "      <td>slow_piano</td>\n",
       "      <td>f7_arpeggios_f_slow_piano_u.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/jake/code/jchaselubitz/vocal_patterns/d...</td>\n",
       "      <td>scales</td>\n",
       "      <td>fast_forte</td>\n",
       "      <td>m8_scales_f_fast_forte_i.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/jake/code/jchaselubitz/vocal_patterns/d...</td>\n",
       "      <td>arpeggios</td>\n",
       "      <td>slow_forte</td>\n",
       "      <td>m9_arpeggios_c_slow_forte_o.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/jake/code/jchaselubitz/vocal_patterns/d...</td>\n",
       "      <td>arpeggios</td>\n",
       "      <td>slow_piano</td>\n",
       "      <td>f4_arpeggios_c_slow_piano_a.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/jake/code/jchaselubitz/vocal_patterns/d...</td>\n",
       "      <td>arpeggios</td>\n",
       "      <td>fast_piano</td>\n",
       "      <td>m6_arpeggios_c_fast_piano_o.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  ...                         filename\n",
       "0  /Users/jake/code/jchaselubitz/vocal_patterns/d...  ...  f7_arpeggios_f_slow_piano_u.wav\n",
       "1  /Users/jake/code/jchaselubitz/vocal_patterns/d...  ...     m8_scales_f_fast_forte_i.wav\n",
       "2  /Users/jake/code/jchaselubitz/vocal_patterns/d...  ...  m9_arpeggios_c_slow_forte_o.wav\n",
       "3  /Users/jake/code/jchaselubitz/vocal_patterns/d...  ...  f4_arpeggios_c_slow_piano_a.wav\n",
       "4  /Users/jake/code/jchaselubitz/vocal_patterns/d...  ...  m6_arpeggios_c_fast_piano_o.wav\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from vocal_patterns.ml_logic.data import get_data\n",
    "\n",
    "data = get_data()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            spectrogram   exercise   technique\n",
      "0     [[0.23180476, 0.2892316, 0.3014535, 0.26719418...  arpeggios  slow_piano\n",
      "1     [[0.2858866, 0.26965076, 0.22097206, 0.2691479...  arpeggios  slow_piano\n",
      "2     [[0.40495643, 0.36227638, 0.28256026, 0.288222...  arpeggios  slow_piano\n",
      "3     [[0.43902367, 0.38572454, 0.3691454, 0.3202114...  arpeggios  slow_piano\n",
      "4     [[0.4204014, 0.3536261, 0.27059212, 0.2587041,...  arpeggios  slow_piano\n",
      "...                                                 ...        ...         ...\n",
      "2102  [[0.4991149, 0.48423472, 0.46026325, 0.4134513...  arpeggios        belt\n",
      "2103  [[0.4130972, 0.3740099, 0.35848665, 0.33925018...  arpeggios        belt\n",
      "2104  [[0.47385788, 0.44830495, 0.39947405, 0.437893...  arpeggios        belt\n",
      "2105  [[0.46448112, 0.42889538, 0.36465287, 0.280395...  arpeggios        belt\n",
      "2106  [[0.45262694, 0.44250888, 0.4067912, 0.4384994...  arpeggios        belt\n",
      "\n",
      "[2107 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spectrogram</th>\n",
       "      <th>exercise</th>\n",
       "      <th>technique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.23180476, 0.2892316, 0.3014535, 0.26719418...</td>\n",
       "      <td>arpeggios</td>\n",
       "      <td>slow_piano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.2858866, 0.26965076, 0.22097206, 0.2691479...</td>\n",
       "      <td>arpeggios</td>\n",
       "      <td>slow_piano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.40495643, 0.36227638, 0.28256026, 0.288222...</td>\n",
       "      <td>arpeggios</td>\n",
       "      <td>slow_piano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.43902367, 0.38572454, 0.3691454, 0.3202114...</td>\n",
       "      <td>arpeggios</td>\n",
       "      <td>slow_piano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.4204014, 0.3536261, 0.27059212, 0.2587041,...</td>\n",
       "      <td>arpeggios</td>\n",
       "      <td>slow_piano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15661</th>\n",
       "      <td>[[0.34217557, 0.40158233, 0.43335074, 0.413529...</td>\n",
       "      <td>scales</td>\n",
       "      <td>slow_forte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15662</th>\n",
       "      <td>[[0.3840975, 0.33667487, 0.3557849, 0.39009723...</td>\n",
       "      <td>scales</td>\n",
       "      <td>slow_forte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15663</th>\n",
       "      <td>[[0.40539208, 0.44813833, 0.43008795, 0.409095...</td>\n",
       "      <td>scales</td>\n",
       "      <td>slow_forte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15664</th>\n",
       "      <td>[[0.3574254, 0.40332788, 0.4217616, 0.4130477,...</td>\n",
       "      <td>scales</td>\n",
       "      <td>slow_forte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15665</th>\n",
       "      <td>[[0.46773988, 0.5213095, 0.49293512, 0.4282013...</td>\n",
       "      <td>scales</td>\n",
       "      <td>slow_forte</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15666 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             spectrogram   exercise   technique\n",
       "0      [[0.23180476, 0.2892316, 0.3014535, 0.26719418...  arpeggios  slow_piano\n",
       "1      [[0.2858866, 0.26965076, 0.22097206, 0.2691479...  arpeggios  slow_piano\n",
       "2      [[0.40495643, 0.36227638, 0.28256026, 0.288222...  arpeggios  slow_piano\n",
       "3      [[0.43902367, 0.38572454, 0.3691454, 0.3202114...  arpeggios  slow_piano\n",
       "4      [[0.4204014, 0.3536261, 0.27059212, 0.2587041,...  arpeggios  slow_piano\n",
       "...                                                  ...        ...         ...\n",
       "15661  [[0.34217557, 0.40158233, 0.43335074, 0.413529...     scales  slow_forte\n",
       "15662  [[0.3840975, 0.33667487, 0.3557849, 0.39009723...     scales  slow_forte\n",
       "15663  [[0.40539208, 0.44813833, 0.43008795, 0.409095...     scales  slow_forte\n",
       "15664  [[0.3574254, 0.40332788, 0.4217616, 0.4130477,...     scales  slow_forte\n",
       "15665  [[0.46773988, 0.5213095, 0.49293512, 0.4282013...     scales  slow_forte\n",
       "\n",
       "[15666 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_with_slices = pd.DataFrame(columns=[\"spectrogram\", \"exercise\", \"technique\"])\n",
    "sample_rate = 22050\n",
    "\n",
    "print(df_with_slices)\n",
    "def scaled_spectrogram(wave_trunc, sr):\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=wave_trunc, sr=sr)\n",
    "    power_to_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    min_value = np.min(power_to_db)\n",
    "    max_value = np.max(power_to_db)\n",
    "\n",
    "    # NORMALIZING gray array so that all values lie between [0, 1]\n",
    "    normalized_spectrogram = (power_to_db - min_value) / (max_value - min_value)\n",
    "\n",
    "    return normalized_spectrogram\n",
    "\n",
    "\n",
    "def slice_waves(waveform, sr, snippet_duration=4, overlap=3):\n",
    "    # Calculate the frame size and hop length\n",
    "    frame_size = int(snippet_duration * sr)\n",
    "    hop_length = int((snippet_duration - overlap) * sr)\n",
    "\n",
    "    # Get the total number of snippets\n",
    "    num_snippets = int(np.floor((len(waveform) - frame_size) / hop_length)) + 1\n",
    "\n",
    "    new_4sec_arrays = []\n",
    "    # Slice the audio into snippets\n",
    "    for i in range(num_snippets):\n",
    "        start_sample = i * hop_length\n",
    "        end_sample = start_sample + frame_size\n",
    "        snippet = waveform[start_sample:end_sample]\n",
    "        # Append the snippet to the list\n",
    "        new_4sec_arrays.append(snippet)\n",
    "\n",
    "    return new_4sec_arrays\n",
    "\n",
    "data_list = []\n",
    "for index, row in data.iterrows():\n",
    "    exercise = row['exercise']\n",
    "    technique = row['technique']\n",
    "    waveform, sr = librosa.load(row[\"path\"], sr=sample_rate)\n",
    "    slice_waveforms = slice_waves(waveform, sr=sample_rate)\n",
    "    for w in slice_waveforms:\n",
    "        normalized_spectrogram = scaled_spectrogram(w, sr=sample_rate)\n",
    "        data_list.append({'spectrogram': normalized_spectrogram, 'exercise': exercise, 'technique': technique})\n",
    "\n",
    "df_with_slices = pd.DataFrame(data_list)\n",
    "df_with_slices\n",
    "\n",
    "# for index, row in data.head(400).iterrows():\n",
    "#     exercise = row['exercise']\n",
    "#     technique = row['technique']\n",
    "#     waveform, sr = librosa.load(row[\"path\"], sr=sample_rate)\n",
    "#     slice_waveforms = slice_waves(waveform, sr=sample_rate)\n",
    "#     for w in slice_waveforms:\n",
    "#         normalized_spectrogram = scaled_spectrogram(w, sr)\n",
    "#         # new_row = {'spectrogram': w, 'exercise': exercise, 'technique': technique}\n",
    "#         df = pd.DataFrame({'spectrogram': w, 'exercise': exercise, 'technique': technique})\n",
    "#         df_with_slices = pd.concat([df_with_slices, df ], ignore_index=True)\n",
    "\n",
    "# return df_with_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1327.2931413650513"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_with_slices[\"exercise\"].value_counts()\n",
    "df_with_slices.memory_usage(deep=True).sum() / (1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['exercise', \"technique\", \"filename\"])\n",
    "y = data[['exercise']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exercise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>arpeggios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>arpeggios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553</th>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>arpeggios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>arpeggios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>arpeggios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>scales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>scales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>arpeggios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>arpeggios</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>867 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       exercise\n",
       "1643  arpeggios\n",
       "382   arpeggios\n",
       "2553      other\n",
       "2213  arpeggios\n",
       "661   arpeggios\n",
       "...         ...\n",
       "2511  arpeggios\n",
       "872      scales\n",
       "1386     scales\n",
       "1924  arpeggios\n",
       "1407  arpeggios\n",
       "\n",
       "[867 rows x 1 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:2677]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from vocal_patterns.interface.main import predict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001    /Users/jake/code/jchaselubitz/vocal_patterns/d...\n",
       "2597    /Users/jake/code/jchaselubitz/vocal_patterns/d...\n",
       "969     /Users/jake/code/jchaselubitz/vocal_patterns/d...\n",
       "1929    /Users/jake/code/jchaselubitz/vocal_patterns/d...\n",
       "1280    /Users/jake/code/jchaselubitz/vocal_patterns/d...\n",
       "Name: path, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[\"path\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test[\"path\"][574]\n",
    "import librosa\n",
    "\n",
    "waveform, sr = librosa.load(X_test[\"path\"][382], sr=22050)\n",
    "X = waveform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Load latest model from local registry...\u001b[0m\n",
      "\u001b[34m\n",
      "Load latest model from disk...\u001b[0m\n",
      "✅ Model loaded from local disk\n",
      "1/1 [==============================] - 0s 102ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "predict(X)\n",
    "# predicted_indices = np.argmax(predict(X), axis=1)\n",
    "# predicted_indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vocal_patterns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
