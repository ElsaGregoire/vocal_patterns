{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5c4c33e-5494-4769-941f-e2a4a4a3120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "sys.path.append('../')\n",
    "from vocal_patterns.ml_logic.preprocessor import preprocess_audio\n",
    "from vocal_patterns.interface import main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3237608-9751-4da1-b79a-4bb80beb216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model functions\n",
    "\n",
    "def initialize_model(input_shape: tuple) -> Model:\n",
    "    \"\"\"\n",
    "    Initialize the CNN model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(8, (5,5), input_shape=input_shape, strides=(2, 2), padding='same', activation=\"relu\"))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Conv2D(16, (3,3), strides=(2, 2), padding='same', activation=\"relu\"))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3,3), strides=(2, 2), padding='same', activation=\"relu\"))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3,3), strides=(2, 2), padding='same', activation=\"relu\"))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "    print(\"✅ Model initialized\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def compile_model(model: Model, learning_rate=0.001) -> Model:\n",
    "    \"\"\"\n",
    "    Compile the Neural Network\n",
    "    \"\"\"\n",
    "    optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    print(\"✅ Model compiled\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e1b1e7c-048a-4ea6-80d9-725555f566d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>exercise</th>\n",
       "      <th>technique</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/denis/code/ElsaGregoire/vocal_patterns/...</td>\n",
       "      <td>Other</td>\n",
       "      <td>vibrato</td>\n",
       "      <td>m6_row_vibrato.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/denis/code/ElsaGregoire/vocal_patterns/...</td>\n",
       "      <td>Other</td>\n",
       "      <td>vibrato</td>\n",
       "      <td>m6_caro_vibrato.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/denis/code/ElsaGregoire/vocal_patterns/...</td>\n",
       "      <td>Other</td>\n",
       "      <td>vibrato</td>\n",
       "      <td>m6_dona_vibrato.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/denis/code/ElsaGregoire/vocal_patterns/...</td>\n",
       "      <td>Other</td>\n",
       "      <td>straight</td>\n",
       "      <td>m6_caro_straight.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/denis/code/ElsaGregoire/vocal_patterns/...</td>\n",
       "      <td>Other</td>\n",
       "      <td>straight</td>\n",
       "      <td>m6_row_straight.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path exercise technique  \\\n",
       "0  /Users/denis/code/ElsaGregoire/vocal_patterns/...    Other   vibrato   \n",
       "1  /Users/denis/code/ElsaGregoire/vocal_patterns/...    Other   vibrato   \n",
       "2  /Users/denis/code/ElsaGregoire/vocal_patterns/...    Other   vibrato   \n",
       "3  /Users/denis/code/ElsaGregoire/vocal_patterns/...    Other  straight   \n",
       "4  /Users/denis/code/ElsaGregoire/vocal_patterns/...    Other  straight   \n",
       "\n",
       "               filename  \n",
       "0    m6_row_vibrato.wav  \n",
       "1   m6_caro_vibrato.wav  \n",
       "2   m6_dona_vibrato.wav  \n",
       "3  m6_caro_straight.wav  \n",
       "4   m6_row_straight.wav  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the data\n",
    "\n",
    "download_path = \"../vocal_patterns/data/dataset_tags.csv\"\n",
    "data = pd.read_csv(download_path)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separate the data\n",
    "\n",
    "X = data.drop(columns=['exercise', \"technique\", \"filename\"])\n",
    "y = data[['exercise']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = preprocess_audio(X_train)\n",
    "X_train_reshaped = X_train_processed.reshape(len(X_train_processed), 128, 259, 1)\n",
    "\n",
    "X_test_processed = preprocess_audio(X_test)\n",
    "X_test_reshaped = X_test_processed.reshape(len(X_test_processed), 128, 259, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denis/.pyenv/versions/3.10.6/envs/vocal_patterns/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_labels = label_encoder.fit_transform(y_train)\n",
    "y_train_cat = to_categorical(y_train_labels, num_classes=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['arpeggios', 'scales', 'Other', ..., 'scales', 'scales',\n",
       "       'arpeggios'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ravel(y_train, order=\"c\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denis/.pyenv/versions/3.10.6/envs/vocal_patterns/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "y_test_labels = label_encoder.transform(y_test)\n",
    "y_test_cat = to_categorical(y_test_labels, num_classes=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model initialized\n",
      "✅ Model compiled\n"
     ]
    }
   ],
   "source": [
    "model = initialize_model((128, 259, 1))\n",
    "model = compile_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 09:51:55.718440: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 3s 39ms/step - loss: 0.5213 - accuracy: 0.7988 - val_loss: 1.0691 - val_accuracy: 0.5217\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.0578 - accuracy: 0.9817 - val_loss: 1.1920 - val_accuracy: 0.3360\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.0239 - accuracy: 0.9936 - val_loss: 1.0186 - val_accuracy: 0.4150\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.5024 - val_accuracy: 0.8538\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3043 - val_accuracy: 0.9071\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 5.3243e-04 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 0.9407\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 3.8522e-04 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9565\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 2.9684e-04 - accuracy: 1.0000 - val_loss: 0.1009 - val_accuracy: 0.9684\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 2.4361e-04 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9743\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 2.0751e-04 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28d9a0970>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_reshaped, y_train_cat, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 13ms/step - loss: 0.1227 - accuracy: 0.9613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12265704572200775, 0.9612545967102051]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_reshaped, y_test_cat, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category Mapping:\n",
      "Other: 0\n",
      "arpeggios: 1\n",
      "scales: 2\n"
     ]
    }
   ],
   "source": [
    "category_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "# Display the mapping\n",
    "print(\"Category Mapping:\")\n",
    "for category, numerical_representation in category_mapping.items():\n",
    "    print(f\"{category}: {numerical_representation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step\n"
     ]
    }
   ],
   "source": [
    "image_to_predict = np.expand_dims(X_test_reshaped[0], axis=0)\n",
    "predictions = model.predict(image_to_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_indices = np.argmax(predictions, axis=1)\n",
    "predicted_indices[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path         /Users/denis/code/ElsaGregoire/vocal_patterns/...\n",
       "exercise                                                 Other\n",
       "technique                                              vibrato\n",
       "filename                                    m6_row_vibrato.wav\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 259)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_processed.shape[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_processed.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model initialized\n",
      "✅ Model compiled\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Epoch 11: early stopping\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1207 - accuracy: 0.9576\n",
      "✅ Results saved locally\n",
      "✅ Model saved locally\n",
      "0.9575645923614502\n"
     ]
    }
   ],
   "source": [
    "model = main.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Load latest model from local registry...\u001b[0m\n",
      "\u001b[34m\n",
      "Load latest model from disk...\u001b[0m\n",
      "✅ Model loaded from local disk\n",
      "34/34 [==============================] - 1s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = main.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5633091e-09, 7.0192131e-05, 9.9992979e-01],\n",
       "       [7.2554840e-08, 2.4952164e-05, 9.9997497e-01],\n",
       "       [6.8502915e-05, 9.9991441e-01, 1.7069622e-05],\n",
       "       ...,\n",
       "       [9.9999917e-01, 8.1291819e-07, 5.6886895e-09],\n",
       "       [4.6224841e-03, 9.9446011e-01, 9.1742870e-04],\n",
       "       [8.3670147e-06, 9.9999166e-01, 1.2424649e-08]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Evaluating model on 1084 rows...\u001b[0m\n",
      "✅ Model evaluated, accuracy: 0.99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.03662455826997757, 'accuracy': 0.9861623644828796}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.evaluate_model(model, X_test_reshaped, y_test_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
